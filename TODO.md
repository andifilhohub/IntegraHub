# IntegraHub - Roadmap & PrÃ³ximos Passos

## âœ… Implementado

### Core Pipeline (100% Funcional)
- [x] API de IngestÃ£o (Fastify)
  - [x] Endpoint POST /v1/inovafarma/products
  - [x] ValidaÃ§Ã£o de headers (X-Inova-Api-Key, X-Inova-Load-Type)
  - [x] Streaming para MinIO
  - [x] IdempotÃªncia automÃ¡tica
  - [x] Graceful shutdown
  - [x] Health check endpoint

- [x] Worker de Chunking
  - [x] Consumer Kafka (batches.received)
  - [x] Download de payload do MinIO
  - [x] DivisÃ£o em chunks de 1000 produtos
  - [x] Upload de chunks para MinIO
  - [x] PublicaÃ§Ã£o de eventos (chunks.ready)

- [x] Workers de Upsert (2-4 instÃ¢ncias)
  - [x] Consumer group Kafka (chunks.ready)
  - [x] Bulk INSERT com ON CONFLICT
  - [x] Suporte a FULL e DELTA loads
  - [x] Soft delete para FULL loads
  - [x] Tracking de progresso de batches

- [x] Worker Orchestrator
  - [x] Gerenciamento de 1 chunker + 2-4 upsert workers
  - [x] Framework de auto-scaling
  - [x] Monitoramento de workers

- [x] Database Schema
  - [x] Tabela Pharmacy
  - [x] Tabela Product (com todos os campos)
  - [x] Tabela batches
  - [x] Tabela batch_chunks
  - [x] Constraints e Ã­ndices

- [x] Infraestrutura de Testes
  - [x] Scripts de teste de carga
  - [x] Teste de pipeline completo
  - [x] Mega stress test (50k requisiÃ§Ãµes)
  - [x] Scripts de monitoramento

---

## ğŸ”§ Melhorias NecessÃ¡rias

### 1. Observabilidade & Monitoramento (Alta Prioridade)

#### MÃ©tricas Prometheus
- [ ] Instrumentar API com prom-client
  - [ ] Contador de requisiÃ§Ãµes por status (202, 400, 500)
  - [ ] Histograma de latÃªncia de upload
  - [ ] Gauge de tamanho de payloads
  - [ ] Contador de batches criados

- [ ] Instrumentar Workers
  - [ ] Gauge de workers ativos
  - [ ] Contador de chunks processados
  - [ ] Histograma de tempo de processamento
  - [ ] Gauge de Kafka lag por consumer group
  - [ ] Contador de erros por tipo

- [ ] MÃ©tricas de NegÃ³cio
  - [ ] Taxa de produtos processados/segundo
  - [ ] Taxa de sucesso de batches
  - [ ] Tempo mÃ©dio de processamento de batch
  - [ ] Produtos ativos vs inativos

#### Dashboard Grafana
- [ ] Criar dashboard de API
  - [ ] RequisiÃ§Ãµes/segundo
  - [ ] LatÃªncia P50, P95, P99
  - [ ] Taxa de erro
  - [ ] Tamanho mÃ©dio de payload

- [ ] Criar dashboard de Workers
  - [ ] Workers ativos vs mÃ¡ximo
  - [ ] Kafka lag
  - [ ] Throughput de produtos
  - [ ] Chunks pendentes vs processados

- [ ] Criar dashboard de NegÃ³cio
  - [ ] Batches por status
  - [ ] CNPJs processados
  - [ ] Produtos ingeridos (24h, 7d, 30d)
  - [ ] Taxa de atualizaÃ§Ã£o vs novos produtos

#### Alertas
- [ ] Kafka lag > 10000 mensagens
- [ ] Taxa de erro da API > 5%
- [ ] Workers crash loop
- [ ] PostgreSQL conexÃµes > 80%
- [ ] MinIO storage > 80%

### 2. ResiliÃªncia & Error Handling (Alta Prioridade)

#### Retry AutomÃ¡tico
- [ ] Implementar retry exponencial para chunks falhados
  - [ ] Max 3 tentativas com backoff
  - [ ] ApÃ³s 3 falhas â†’ Dead Letter Queue

- [ ] Dead Letter Queue (DLQ)
  - [ ] TÃ³pico Kafka: chunks.failed
  - [ ] Worker dedicado para anÃ¡lise de falhas
  - [ ] Interface para reprocessamento manual

#### Circuit Breaker
- [ ] Implementar circuit breaker para:
  - [ ] ConexÃµes com MinIO
  - [ ] ConexÃµes com PostgreSQL
  - [ ] ConexÃµes com Kafka

#### Health Checks AvanÃ§ados
- [ ] Health check detalhado da API
  - [ ] Verificar conectividade Kafka
  - [ ] Verificar conectividade MinIO
  - [ ] Verificar conectividade PostgreSQL
  - [ ] Retornar status 503 se algum serviÃ§o estÃ¡ down

- [ ] Liveness probe para workers
- [ ] Readiness probe para workers

### 3. Performance & OtimizaÃ§Ãµes (MÃ©dia Prioridade)

#### Database
- [ ] Adicionar Ã­ndices adicionais
  - [ ] `Product(cnpj, lastSeenAt)` para FULL loads
  - [ ] `batches(status, created_at)` para queries
  - [ ] `batch_chunks(batch_id, status)` para tracking

- [ ] Connection pooling otimizado
  - [ ] Ajustar min/max connections por worker
  - [ ] Implementar pool connection reuse

- [ ] Query optimization
  - [ ] Usar COPY ao invÃ©s de multi-row INSERT (se necessÃ¡rio)
  - [ ] Batch updates para batch progress
  - [ ] Preparar statements reutilizÃ¡veis

#### Kafka
- [ ] Configurar partiÃ§Ãµes adequadas
  - [ ] batches.received: 10 partiÃ§Ãµes (para paralelismo)
  - [ ] chunks.ready: 20 partiÃ§Ãµes (mais workers)

- [ ] Tuning de consumer
  - [ ] Ajustar fetch.min.bytes
  - [ ] Ajustar fetch.max.wait.ms
  - [ ] Ajustar max.poll.records

- [ ] CompressÃ£o de mensagens
  - [ ] Habilitar compression.type=snappy no producer

#### MinIO
- [ ] Lifecycle policies
  - [ ] Expirar payloads apÃ³s 30 dias
  - [ ] Mover chunks para cold storage apÃ³s 7 dias

- [ ] Otimizar uploads
  - [ ] Multipart upload para payloads > 5MB
  - [ ] Connection reuse

### 4. SeguranÃ§a (MÃ©dia Prioridade)

#### API Security
- [ ] Rate limiting por API key
  - [ ] Limite: 100 req/min por CNPJ
  - [ ] Retornar 429 Too Many Requests

- [ ] ValidaÃ§Ã£o de payload
  - [ ] JSON Schema validation
  - [ ] Tamanho mÃ¡ximo por produto
  - [ ] ValidaÃ§Ã£o de CNPJ format

- [ ] HTTPS obrigatÃ³rio
  - [ ] Configurar TLS certificates
  - [ ] Redirect HTTP â†’ HTTPS

#### Infrastructure Security
- [ ] Secrets management
  - [ ] Migrar para AWS Secrets Manager / Vault
  - [ ] RotaÃ§Ã£o automÃ¡tica de credenciais

- [ ] Network policies
  - [ ] Workers â†’ PostgreSQL only
  - [ ] API â†’ MinIO + Kafka + PostgreSQL
  - [ ] Nenhum acesso externo direto

### 5. Auto-scaling Real (MÃ©dia Prioridade)

#### Implementar auto-scaling baseado em mÃ©tricas
- [ ] Escalar workers baseado em Kafka lag
  - [ ] Lag > 5000: adicionar 1 worker
  - [ ] Lag < 1000: remover 1 worker
  - [ ] Min: 2 workers, Max: 16 workers

- [ ] Escalar API baseado em CPU/memÃ³ria
  - [ ] CPU > 70%: adicionar 1 instÃ¢ncia
  - [ ] CPU < 30%: remover 1 instÃ¢ncia
  - [ ] Min: 2 instÃ¢ncias, Max: 10 instÃ¢ncias

### 6. Features Adicionais (Baixa Prioridade)

#### Webhook de NotificaÃ§Ã£o
- [ ] Notificar cliente quando batch completo
  - [ ] POST para webhook_url configurado
  - [ ] Payload: batch_id, status, items_processed, timestamp

#### API de Consulta
- [ ] Endpoint GET /v1/batches/:batch_id
  - [ ] Status do batch
  - [ ] Progresso (X/Y produtos processados)
  - [ ] Tempo estimado de conclusÃ£o

- [ ] Endpoint GET /v1/products
  - [ ] Buscar produtos por CNPJ
  - [ ] Filtros: category, price range, stock
  - [ ] PaginaÃ§Ã£o

#### Interface de AdministraÃ§Ã£o
- [ ] Dashboard web para monitoramento
  - [ ] Lista de batches (Ãºltimas 24h)
  - [ ] GrÃ¡ficos de throughput
  - [ ] Logs de erros
  - [ ] Reprocessar batches falhados

### 7. Testes (MÃ©dia Prioridade)

#### Testes Automatizados
- [ ] Unit tests
  - [ ] Bulk operations
  - [ ] Chunk generation
  - [ ] Payload validation

- [ ] Integration tests
  - [ ] API â†’ MinIO â†’ Kafka flow
  - [ ] Worker â†’ PostgreSQL flow
  - [ ] End-to-end pipeline test

- [ ] Load tests
  - [ ] 100k requisiÃ§Ãµes simultÃ¢neas
  - [ ] 1M produtos em 1 batch
  - [ ] 10 CNPJs enviando simultaneamente

#### CI/CD
- [ ] GitHub Actions
  - [ ] Run tests on PR
  - [ ] Build Docker images
  - [ ] Deploy to staging on merge to main
  - [ ] Deploy to production on tag

### 8. DocumentaÃ§Ã£o (Baixa Prioridade)

- [ ] OpenAPI/Swagger spec para API
- [ ] Diagramas de arquitetura atualizados
- [ ] Runbook para operaÃ§Ãµes
  - [ ] Como reiniciar workers
  - [ ] Como reprocessar batch falhado
  - [ ] Como fazer rollback
- [ ] SLA e SLO definidos

---

## ğŸ¯ Prioridades para as PrÃ³ximas Sprints

### Sprint 1 (1-2 semanas)
1. âœ… Deploy em produÃ§Ã£o (bÃ¡sico)
2. âš ï¸ Observabilidade bÃ¡sica (Prometheus + Grafana)
3. âš ï¸ Health checks avanÃ§ados
4. âš ï¸ Retry automÃ¡tico para chunks falhados

### Sprint 2 (2-3 semanas)
1. Auto-scaling baseado em Kafka lag
2. Dead Letter Queue
3. Rate limiting na API
4. Testes de carga 100k requisiÃ§Ãµes

### Sprint 3 (3-4 semanas)
1. Webhook de notificaÃ§Ã£o
2. API de consulta de batches
3. Dashboard de administraÃ§Ã£o
4. DocumentaÃ§Ã£o completa

---

## ğŸ“Š KPIs a Medir

### Performance
- Throughput: **> 10,000 produtos/segundo**
- LatÃªncia API P95: **< 500ms**
- LatÃªncia processamento batch: **< 5 minutos** (para batches de 10k produtos)

### Confiabilidade
- Uptime API: **> 99.9%**
- Taxa de sucesso de batches: **> 99.5%**
- Taxa de retry bem-sucedidos: **> 95%**

### Escalabilidade
- Suporte a **1000 CNPJs simultÃ¢neos**
- Suporte a **100k requisiÃ§Ãµes/dia**
- Suporte a **10M produtos/dia**

---

**Status Geral**: Sistema em **produÃ§Ã£o-ready** para cargas mÃ©dias. Necessita observabilidade e resiliÃªncia para cargas massivas em produÃ§Ã£o.
